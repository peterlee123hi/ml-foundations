{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b26d625",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "This notebook builds a simple linear regression model.\n",
    "- Derives the MLE solution for estimating weights under Gaussian noise\n",
    "- Implements Bayesian inference with Gaussian priors\n",
    "- Visualizes predictive uncertainty from the posterior\n",
    "- Animates gradient descent optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be974ab",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa38830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0ac6d",
   "metadata": {},
   "source": [
    "## MLE for Linear Regression with Gaussian Noise\n",
    "\n",
    "We're modeling outputs of $y \\in \\mathbb{R}^n$ as noisy linear combinations of inputs $X \\in \\mathbb{R}^{n \\times d}$:\n",
    "\n",
    "$$y = X w + \\epsilon$$\n",
    "\n",
    "Where: \n",
    "- $x_i \\in \\mathbb{R}^d$ is the $i$-th row of $X$, representing one data point\n",
    "- $w \\in \\mathbb{R}^d$ is the parameter vector\n",
    "- Each output $y_i$ is given by $y_i = x_i^T w + \\epsilon_i$\n",
    "- The noise term $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_n)$ is i.i.d. gaussian\n",
    "\n",
    "Conditioned on $X$, the outputs are:\n",
    "\n",
    "$$y \\mid X \\sim \\mathbb{N}(X w, \\sigma^2 I)$$\n",
    "\n",
    "When $d = 1$, we are fitting a line and when $d = 2$, we are fitting a plane. Also, note that there is no bias term although that could be added by adjusting the model.\n",
    "\n",
    "$$X' = \\begin{bmatrix} X & \\mathbf{1} \\end{bmatrix}, w' = \\begin{bmatrix} w \\\\ b \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4173f",
   "metadata": {},
   "source": [
    "### Likelihood\n",
    "\n",
    "The probability density function of $y$ is the following.\n",
    "\n",
    "$$ p(y | X, w, \\sigma^2) = \\prod_{i=1}^{n} \\mathcal{N}(y_i | x_i^T w, \\sigma^2)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\\mathcal{N}(y_i | x_i^T, w, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp (-\\frac{1}{2 \\sigma^2} (y_i - x_i^T w)^2)$$\n",
    "\n",
    "When we want the log-likelihood and remove the constants, we get the following.\n",
    "\n",
    "$$\\log(p(y | X, w, \\sigma^2)) \\sim -\\sum_{i=1}^{n} (y_i - x_i^T w)^2 \\sim -||y - Xw||^2$$\n",
    "\n",
    "This means that maximizing the log-likelihood is equivalent to minimizing the squared error.\n",
    "\n",
    "$$\\min_{w} ||y - Xw||^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8429dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3520653267642995)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussian_pdf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    Gaussian probability density function\n",
    "\n",
    "    Args:\n",
    "        x: point(s) to get the probability of generating from a normal distribution\n",
    "        mu: mean of the normal distribution\n",
    "        sigma: standard deviation of the normal distribution\n",
    "\n",
    "    Returns:\n",
    "        The probability density at x\n",
    "    \"\"\"\n",
    "    coef = 1 / (np.sqrt(2 * np.pi * sigma ** 2))\n",
    "    exponent = -((x - mu) ** 2 / (2 * sigma ** 2))\n",
    "    return coef * np.exp(exponent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
